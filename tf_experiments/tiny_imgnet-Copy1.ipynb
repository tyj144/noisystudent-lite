{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/guide/keras/preprocessing_layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-09ca5e9c20a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Add the rest of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m model = keras.applications.ResNet50(\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/noisystudent-lite/venv/lib/python3.6/site-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m   return ResNet(stack_fn, False, True, 'resnet50', include_top, weights,\n\u001b[0;32m--> 475\u001b[0;31m                 input_tensor, input_shape, pooling, classes, **kwargs)\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/noisystudent-lite/venv/lib/python3.6/site-packages/tensorflow/python/keras/applications/resnet.py\u001b[0m in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'imagenet'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minclude_top\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n\u001b[0m\u001b[1;32m    148\u001b[0m                      ' as true, `classes` should be 1000')\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000"
     ]
    }
   ],
   "source": [
    "# Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
    "# data_augmentation = keras.Sequential(\n",
    "#     [\n",
    "#         preprocessing.RandomFlip(\"horizontal\"),\n",
    "#         preprocessing.RandomRotation(0.1),\n",
    "#         preprocessing.RandomZoom(0.1),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# Create a model that includes the augmentation stage\n",
    "input_shape = (64, 64, 3)\n",
    "classes = 200\n",
    "# inputs = keras.Input(shape=input_shape)\n",
    "# Augment images\n",
    "# x = data_augmentation(inputs)\n",
    "# # Rescale image values to [0, 1]\n",
    "# x = preprocessing.Rescaling(1.0 / 255)(x)\n",
    "# Add the rest of the model\n",
    "model = keras.applications.ResNet50(\n",
    "    weights='imagenet', include_top=True, input_shape=input_shape, classes=classes\n",
    ")\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100000 images belonging to 200 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load some data\n",
    "TINY_IMAGENET_PATH = 'datasets/tiny-imagenet-200'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_iterator = train_datagen.flow_from_directory(\n",
    "    f'{TINY_IMAGENET_PATH}/train', target_size=(64, 64), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (32, 64, 64, 3)\n",
      "y (32,)\n",
      "probs (32, 200)\n",
      "[[[0.4930717  0.15398714 0.12653616]\n",
      "  [0.4930738  0.15398505 0.12653407]\n",
      "  [0.49307588 0.15398295 0.12653197]\n",
      "  ...\n",
      "  [0.09010088 0.16160733 0.11730312]\n",
      "  [0.0901637  0.16166806 0.11735757]\n",
      "  [0.09022653 0.1617288  0.11741202]]\n",
      "\n",
      " [[0.49339464 0.1600613  0.13261032]\n",
      "  [0.4933821  0.16004872 0.13259774]\n",
      "  [0.49336952 0.16003616 0.13258518]\n",
      "  ...\n",
      "  [0.00972801 0.08423782 0.05178104]\n",
      "  [0.00967775 0.08418755 0.05171611]\n",
      "  [0.00962748 0.08413729 0.05165118]]\n",
      "\n",
      " [[0.5138873  0.18057412 0.1530625 ]\n",
      "  [0.51387054 0.18055527 0.15304993]\n",
      "  [0.5138537  0.18053642 0.15303735]\n",
      "  ...\n",
      "  [0.09153672 0.16604653 0.15745062]\n",
      "  [0.09148645 0.16599627 0.15738569]\n",
      "  [0.09143619 0.16594599 0.15732077]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.513114   0.21324001 0.16348276]\n",
      "  [0.5131223  0.21327353 0.1634995 ]\n",
      "  [0.5131307  0.21330704 0.16351625]\n",
      "  ...\n",
      "  [0.2030166  0.13433887 0.06475616]\n",
      "  [0.20301032 0.13433677 0.06475197]\n",
      "  [0.20300403 0.13433468 0.06474778]]\n",
      "\n",
      " [[0.5056833  0.16738664 0.14117648]\n",
      "  [0.5056707  0.16739082 0.14117648]\n",
      "  [0.50565815 0.16739501 0.14117648]\n",
      "  ...\n",
      "  [0.21127208 0.13577695 0.06911027]\n",
      "  [0.21127416 0.13578323 0.06911656]\n",
      "  [0.21127626 0.13578951 0.06912284]]\n",
      "\n",
      " [[0.5273184  0.1618597  0.14278956]\n",
      "  [0.52728283 0.16183877 0.14275815]\n",
      "  [0.5272472  0.16181782 0.14272673]\n",
      "  ...\n",
      "  [0.20786336 0.12555085 0.05888418]\n",
      "  [0.20786546 0.12555714 0.05889047]\n",
      "  [0.20786755 0.12556341 0.05889675]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, (x, y) in enumerate(train_iterator):\n",
    "    if i == 1:\n",
    "        # print(x)\n",
    "        print('x', x.shape)\n",
    "        # print(y)\n",
    "        print('y', y.shape)\n",
    "        probabilities = model.call(tf.convert_to_tensor(x))\n",
    "        print('probs', probabilities.shape)\n",
    "        dim = 10\n",
    "        plt.imshow((x[0] * 255).astype('uint8'))\n",
    "        print(x[0])\n",
    "#         plt.figure()\n",
    "\n",
    "#         figure, axes = plt.subplots(dim, dim)\n",
    "#         print(axes)\n",
    "#         for i, axes_row in enumerate(axes):\n",
    "#             for j, ax in enumerate(axes_row):\n",
    "#                 ax.imshow(x[i * dim + j])\n",
    "#         plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "val_iterator = val_datagen.flow_from_directory(\n",
    "    f'{TINY_IMAGENET_PATH}/val', target_size=(64, 64), batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights using a checkpoint.\n",
    "filepath = \"weights/\" + f\"{datetime.datetime.now()}\" + \"/weights-improvement-{epoch:02d}-{acc:.2f}.hdf5\"\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='acc',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 205s 2s/step - loss: 7.1240 - acc: 0.0053\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 194s 2s/step - loss: 6.1174 - acc: 0.0050\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 190s 2s/step - loss: 5.6501 - acc: 0.0078\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 184s 2s/step - loss: 5.4520 - acc: 0.0119\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 182s 2s/step - loss: 5.2944 - acc: 0.0159\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 204s 2s/step - loss: 5.1946 - acc: 0.0188\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 230s 2s/step - loss: 5.1519 - acc: 0.0247\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 205s 2s/step - loss: 5.0764 - acc: 0.0266\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 209s 2s/step - loss: 5.0133 - acc: 0.0281\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 220s 2s/step - loss: 5.0115 - acc: 0.0347\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 188s 2s/step - loss: 4.9444 - acc: 0.0381\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 220s 2s/step - loss: 4.9542 - acc: 0.0391\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 223s 2s/step - loss: 4.9627 - acc: 0.0381\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 210s 2s/step - loss: 4.9112 - acc: 0.0397\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 178s 2s/step - loss: 4.8674 - acc: 0.0431\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 206s 2s/step - loss: 4.8632 - acc: 0.0419\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 222s 2s/step - loss: 4.7452 - acc: 0.0484\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 179s 2s/step - loss: 4.7186 - acc: 0.0525\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 177s 2s/step - loss: 4.7022 - acc: 0.0591\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 194s 2s/step - loss: 4.6329 - acc: 0.0631\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 208s 2s/step - loss: 4.5499 - acc: 0.0647\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 245s 2s/step - loss: 4.5590 - acc: 0.0725\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 218s 2s/step - loss: 4.5668 - acc: 0.0634\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 225s 2s/step - loss: 4.5209 - acc: 0.0706\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 226s 2s/step - loss: 4.4542 - acc: 0.0737\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 196s 2s/step - loss: 4.4435 - acc: 0.0737\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 193s 2s/step - loss: 4.4353 - acc: 0.0778\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 201s 2s/step - loss: 4.3876 - acc: 0.0891\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 387s 4s/step - loss: 4.3766 - acc: 0.0844\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 371s 4s/step - loss: 4.5685 - acc: 0.0666\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 380s 4s/step - loss: 4.4371 - acc: 0.0756\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 566s 6s/step - loss: 4.3833 - acc: 0.0919\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 289s 3s/step - loss: 4.2984 - acc: 0.0925\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 280s 3s/step - loss: 4.3362 - acc: 0.0866\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 2666s 27s/step - loss: 4.3460 - acc: 0.0966\n",
      "Epoch 36/100\n",
      " 32/100 [========>.....................] - ETA: 3:25 - loss: 4.3491 - acc: 0.0820"
     ]
    }
   ],
   "source": [
    "STEPS_PER_EPOCH = 100\n",
    "VALIDATION_STEPS = 100\n",
    "EPOCHS = 100\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.fit(\n",
    "    train_iterator,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_list,\n",
    "#     validation_data=val_iterator,\n",
    "#     validation_steps=VALIDATION_STEPS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n",
      " 125 125 125 125 125 125 125 125 125 125 125 125 125 125], shape=(32,), dtype=int64)\n",
      "probs\n",
      "tf.Tensor(\n",
      "[[0.00468092 0.00480742 0.00489825 ... 0.00528535 0.00488901 0.00489195]\n",
      " [0.00464835 0.00481394 0.0048884  ... 0.0052732  0.0048697  0.00488988]\n",
      " [0.00473733 0.00486978 0.00491996 ... 0.00520353 0.00492405 0.0048703 ]\n",
      " ...\n",
      " [0.00470506 0.00481662 0.0049167  ... 0.00520628 0.00491397 0.00491045]\n",
      " [0.00464217 0.00482561 0.00489362 ... 0.00531026 0.00484166 0.00486838]\n",
      " [0.00482032 0.00490528 0.0049256  ... 0.00514072 0.00493652 0.0049467 ]], shape=(32, 200), dtype=float32)\n",
      "tf.Tensor(5.2981734, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n",
      " 125 125 125 125 125 125 125 125 125 125 125 125 125 125], shape=(32,), dtype=int64)\n",
      "probs\n",
      "tf.Tensor(\n",
      "[[0.00468735 0.00486574 0.00489959 ... 0.0052852  0.00489437 0.00489253]\n",
      " [0.0046489  0.0047882  0.00486598 ... 0.00533301 0.00486656 0.00487892]\n",
      " [0.00463835 0.00477269 0.00485666 ... 0.00533215 0.00486547 0.00491048]\n",
      " ...\n",
      " [0.00473623 0.0048302  0.00489422 ... 0.00524508 0.00490689 0.00490697]\n",
      " [0.00470922 0.00483884 0.00488495 ... 0.00529197 0.00489095 0.0048884 ]\n",
      " [0.00467365 0.00481234 0.00489137 ... 0.00527824 0.00487345 0.00489002]], shape=(32, 200), dtype=float32)\n",
      "tf.Tensor(5.299552, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n",
      " 125 125 125 125 125 125 125 125 125 125 125 125 125 125], shape=(32,), dtype=int64)\n",
      "probs\n",
      "tf.Tensor(\n",
      "[[0.00468067 0.00483829 0.00486628 ... 0.00530381 0.00488024 0.00488355]\n",
      " [0.00473284 0.00486268 0.00489087 ... 0.00522893 0.00487802 0.00491169]\n",
      " [0.00464413 0.00478529 0.00487365 ... 0.00534068 0.00487056 0.00487741]\n",
      " ...\n",
      " [0.00467245 0.00478186 0.00488667 ... 0.00533127 0.00490086 0.00487049]\n",
      " [0.00475366 0.00483981 0.00486354 ... 0.00526022 0.00488911 0.00493089]\n",
      " [0.00466883 0.00480628 0.00483614 ... 0.00535023 0.00485074 0.00492105]], shape=(32, 200), dtype=float32)\n",
      "tf.Tensor(5.297933, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n",
      " 125 125 125 125 125 125 125 125 125 125 125 125 125 125], shape=(32,), dtype=int64)\n",
      "probs\n",
      "tf.Tensor(\n",
      "[[0.00479652 0.00486456 0.00489967 ... 0.00521721 0.00494406 0.00495552]\n",
      " [0.00458466 0.00477828 0.00483771 ... 0.00539341 0.00487142 0.00488022]\n",
      " [0.00470277 0.00483591 0.00488378 ... 0.00528869 0.00490106 0.00494401]\n",
      " ...\n",
      " [0.00464748 0.00477554 0.00483987 ... 0.00535305 0.00489507 0.00489434]\n",
      " [0.00477423 0.00486513 0.00489557 ... 0.00523814 0.00492012 0.00493813]\n",
      " [0.00470036 0.00483424 0.00488563 ... 0.00528721 0.00490087 0.00490733]], shape=(32, 200), dtype=float32)\n",
      "tf.Tensor(5.302044, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n",
      " 125 125 125 125 125 125 125 125 125 125 125 125 125 125], shape=(32,), dtype=int64)\n",
      "probs\n",
      "tf.Tensor(\n",
      "[[0.00471006 0.00481854 0.00489308 ... 0.00525588 0.00494402 0.00489709]\n",
      " [0.00470586 0.00484244 0.00490478 ... 0.00526478 0.00491087 0.00491146]\n",
      " [0.00461388 0.00479321 0.00491078 ... 0.00537467 0.0048867  0.00487623]\n",
      " ...\n",
      " [0.00467491 0.00483773 0.00489479 ... 0.00528715 0.00490749 0.00490952]\n",
      " [0.00477032 0.00491342 0.00492144 ... 0.00519357 0.00493221 0.00494067]\n",
      " [0.00458696 0.00475444 0.00486492 ... 0.00540229 0.00486484 0.00487688]], shape=(32, 200), dtype=float32)\n",
      "tf.Tensor(5.300132, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n",
      " 125 125 125 125 125 125 125 125 125 125 125 125 125 125], shape=(32,), dtype=int64)\n",
      "probs\n",
      "tf.Tensor(\n",
      "[[0.00477677 0.00484198 0.00495653 ... 0.00521119 0.00491485 0.00493611]\n",
      " [0.00461336 0.00473388 0.00494217 ... 0.00535635 0.00488369 0.0048743 ]\n",
      " [0.00458166 0.00477761 0.00490221 ... 0.00535129 0.00486859 0.00487568]\n",
      " ...\n",
      " [0.00470985 0.00481448 0.00496363 ... 0.00526278 0.00490204 0.0049303 ]\n",
      " [0.00474222 0.004877   0.00496681 ... 0.00520231 0.0049506  0.00492155]\n",
      " [0.00482432 0.00490919 0.00501116 ... 0.00512677 0.00493449 0.0049429 ]], shape=(32, 200), dtype=float32)\n",
      "tf.Tensor(5.296446, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n",
      " 125 125 125 125 125 125 125 125 125 125 125 125 125 125], shape=(32,), dtype=int64)\n",
      "probs\n",
      "tf.Tensor(\n",
      "[[0.00467711 0.0048139  0.00496418 ... 0.00527288 0.00492513 0.00491773]\n",
      " [0.00473674 0.00483736 0.00495016 ... 0.00521475 0.00491672 0.00493725]\n",
      " [0.00474493 0.00484048 0.00497599 ... 0.00522334 0.00491928 0.00491837]\n",
      " ...\n",
      " [0.00471688 0.00483014 0.00492345 ... 0.00527343 0.00487768 0.00489712]\n",
      " [0.00470561 0.00482264 0.00495556 ... 0.00524835 0.00490986 0.00491082]\n",
      " [0.00464217 0.00479445 0.00494653 ... 0.00531657 0.00488143 0.00486122]], shape=(32, 200), dtype=float32)\n",
      "tf.Tensor(5.2934227, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n",
      " 125 125 125 125 125 125 125 125 125 125 125 125 125 125], shape=(32,), dtype=int64)\n",
      "probs\n",
      "tf.Tensor(\n",
      "[[0.00481786 0.00492805 0.00497869 ... 0.00515841 0.00492962 0.00494338]\n",
      " [0.00469441 0.00487815 0.00497126 ... 0.0052574  0.00490146 0.00489398]\n",
      " [0.0045108  0.00475674 0.00490817 ... 0.00539148 0.00484601 0.00483787]\n",
      " ...\n",
      " [0.00464792 0.00483758 0.00494047 ... 0.00523647 0.00489391 0.00488832]\n",
      " [0.00471653 0.00490452 0.00494942 ... 0.00522299 0.00491866 0.00491739]\n",
      " [0.00465001 0.00487858 0.00493526 ... 0.00525308 0.00488012 0.0049079 ]], shape=(32, 200), dtype=float32)\n",
      "tf.Tensor(5.2923527, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n",
      " 125 125 125 125 125 125 125 125 125 125 125 125 125 125], shape=(32,), dtype=int64)\n",
      "probs\n",
      "tf.Tensor(\n",
      "[[0.00461927 0.00487517 0.00491561 ... 0.00535968 0.00490437 0.0048946 ]\n",
      " [0.0046181  0.00475179 0.00493407 ... 0.00537474 0.00489399 0.00483656]\n",
      " [0.00465985 0.00485181 0.00492716 ... 0.0053153  0.00495227 0.00487932]\n",
      " ...\n",
      " [0.00464191 0.00484348 0.00500518 ... 0.00532565 0.00487443 0.00488576]\n",
      " [0.00466448 0.00483941 0.00492163 ... 0.00528285 0.00493253 0.00491169]\n",
      " [0.00462319 0.00479589 0.00490589 ... 0.00539357 0.00491994 0.00488034]], shape=(32, 200), dtype=float32)\n",
      "tf.Tensor(5.296879, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n",
      " 125 125 125 125 125 125 125 125 125 125 125 125 125 125], shape=(32,), dtype=int64)\n",
      "probs\n",
      "tf.Tensor(\n",
      "[[0.00467328 0.00484648 0.0049622  ... 0.0053236  0.00494764 0.00490248]\n",
      " [0.00477937 0.00487435 0.0049648  ... 0.00523697 0.00494079 0.00493177]\n",
      " [0.00473388 0.00486112 0.0049343  ... 0.00529418 0.00493797 0.00491628]\n",
      " ...\n",
      " [0.0047125  0.00484314 0.0049467  ... 0.00531024 0.00491266 0.00491751]\n",
      " [0.00474296 0.00486363 0.00497201 ... 0.00529754 0.00492334 0.00493128]\n",
      " [0.00471966 0.00485787 0.0049568  ... 0.00531499 0.00493742 0.00490946]], shape=(32, 200), dtype=float32)\n",
      "tf.Tensor(5.3043413, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n",
      " 125 125 125 125 125 125 125 125 125 125 125 125 161 125], shape=(32,), dtype=int64)\n",
      "probs\n",
      "tf.Tensor(\n",
      "[[0.00471887 0.0048366  0.00492414 ... 0.00533964 0.00495653 0.00488805]\n",
      " [0.00467957 0.00481856 0.00490784 ... 0.00534714 0.00491428 0.0048936 ]\n",
      " [0.00467614 0.0048166  0.00493344 ... 0.0053423  0.00495879 0.00485965]\n",
      " ...\n",
      " [0.00461434 0.00478836 0.00491572 ... 0.00540394 0.00494109 0.00483944]\n",
      " [0.00487555 0.00492763 0.00499512 ... 0.00517062 0.00501886 0.00494648]\n",
      " [0.00465221 0.00479514 0.00490611 ... 0.00537734 0.00492397 0.00488261]], shape=(32, 200), dtype=float32)\n",
      "tf.Tensor(5.295146, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125 125\n",
      " 125 125 125 125 125 125 125 125 125 125 125 125 125 125], shape=(32,), dtype=int64)\n",
      "probs\n",
      "tf.Tensor(\n",
      "[[0.0047136  0.00485193 0.00493234 ... 0.00537085 0.00494043 0.00487313]\n",
      " [0.00466662 0.00486786 0.00491749 ... 0.00543502 0.00490566 0.00485466]\n",
      " [0.00455228 0.00481952 0.00490766 ... 0.0054521  0.00488317 0.00480722]\n",
      " ...\n",
      " [0.00468688 0.00484395 0.00491274 ... 0.00536108 0.0048808  0.004902  ]\n",
      " [0.00471503 0.00486688 0.00492983 ... 0.00534479 0.00492606 0.00489529]\n",
      " [0.00479638 0.00488317 0.00494276 ... 0.00528512 0.00495879 0.0049057 ]], shape=(32, 200), dtype=float32)\n",
      "tf.Tensor(5.305435, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ee4d8fbce0d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         print(tf.reduce_mean(predictions == y))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;31m#         print(gradients[0][0][0][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/noisystudent-lite/venv/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/noisystudent-lite/venv/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/dev/noisystudent-lite/venv/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/noisystudent-lite/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    594\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m           data_format=data_format),\n\u001b[0m\u001b[1;32m    597\u001b[0m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[1;32m    598\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/noisystudent-lite/venv/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_input\u001b[0;34m(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1253\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = keras.applications.ResNet50(\n",
    "#     weights=None, include_top=True, input_shape=input_shape, classes=classes\n",
    "# )\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "for batch_i, (x, y) in enumerate(train_iterator):    \n",
    "    with tf.GradientTape() as tape:\n",
    "#         print(x)\n",
    "        probs = model.call(tf.convert_to_tensor(x), training=True)\n",
    "#         print(probabilities.shape)\n",
    "#         print(predictions.dtype)\n",
    "#         print(y.dtype)\n",
    "#         y = tf.cast(y, tf.int64)\n",
    "#         print(y.dtype)\n",
    "#         l = tf.keras.losses.sparse_categorical_crossentropy(y, probabilities)\n",
    "        l = tf.reduce_mean(tf.keras.losses.sparse_categorical_crossentropy(y, probs))\n",
    "#         print('y')\n",
    "#         print(y)\n",
    "        predictions = tf.argmax(probs, 1)\n",
    "#         print('predictions')\n",
    "        print(predictions)\n",
    "        print('probs')\n",
    "        print(probs)\n",
    "        print(l)\n",
    "#         print(tf.reduce_mean(predictions == y))\n",
    "        gradients = tape.gradient(l, model.trainable_variables)\n",
    "#         print(gradients[0][0][0][0])\n",
    "        optimizer.apply_gradients(zip(gradients * 1000, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of batches:', len(train_iterator))\n",
    "print('batch size:', 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy\n",
    "# count = 0\n",
    "tf_count = 0\n",
    "for batch_i, (x, y) in enumerate(train_iterator):\n",
    "    probabilities = model.call(tf.convert_to_tensor(x))\n",
    "    predictions = tf.argmax(probabilities, 1)\n",
    "    \n",
    "    tf_count += tf.reduce_sum(tf.cast(predictions == y, tf.float32))\n",
    "    if batch_i % 50 == 0:\n",
    "        print('reduce_sum:', tf_count.numpy(), '/', (batch_i + 1) * 32)\n",
    "        \n",
    "print(tf_count / (len(train_iterator) * 32))\n",
    "    \n",
    "#     for i in range(len(predictions)):\n",
    "#         if predictions[i] == y[i]:\n",
    "#             count += 1\n",
    "#     print('manual:', count, '/', (batch_i + 1) * 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"weights/model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the saved model\n",
    "WEIGHTS_NAME = 'weights-improvement-01-0.00.hdf5'\n",
    "model.load_weights(f'weights/{WEIGHTS_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
