{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudolabel images with a teacher model\n",
    "Load in a model trained on the (smaller) CUB 200 2010 set and pseudolabel images on larger CUB 200 2011 set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import datetime\n",
    "from src.shared import weights_path, data_path, gen_train_val, data_transforms, should_print\n",
    "from src.PseudolabelDataset import PseudolabelDataset\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_local = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of weights transfered from CCV\n",
    "TRAINED_MODEL_PATH = \"weights/resnet50_CUB200_66pct\"\n",
    "# TRAINED_MODEL_PATH = \"weights/student_CUB200_Dec4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/users/tjiang12/data/tjiang12/CUB_200'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-e6ad87b533bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlabeled_data_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_dataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m labeled_dataset = datasets.ImageFolder(\n\u001b[0;32m----> 5\u001b[0;31m     labeled_data_dir, data_transforms['train'])\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlabeled_image_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_train_val\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeled_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/noisystudent-lite/torch/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/noisystudent-lite/torch/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    106\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m    107\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/noisystudent-lite/torch/lib/python3.6/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mNo\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubdirectory\u001b[0m \u001b[0mof\u001b[0m \u001b[0manother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/users/tjiang12/data/tjiang12/CUB_200'"
     ]
    }
   ],
   "source": [
    "# Load smaller labeled set (CUB 200 2010)\n",
    "labeled_dataset_name = \"CUB_200\"\n",
    "labeled_data_dir = data_path(labeled_dataset_name)\n",
    "labeled_dataset = datasets.ImageFolder(\n",
    "    labeled_data_dir, data_transforms['train'])\n",
    "\n",
    "labeled_image_datasets = gen_train_val(labeled_dataset)\n",
    "labeled_dataloaders = {x: torch.utils.data.DataLoader(labeled_image_datasets[x], batch_size=BATCH_SIZE,\n",
    "                                              shuffle=True)\n",
    "               for x in ['train', 'val']}\n",
    "labeled_dataset_sizes = {x: len(labeled_image_datasets[x]) for x in ['train', 'val']}\n",
    "\n",
    "class_names = labeled_dataset.classes\n",
    "\n",
    "# Load larger unlabeled set (CUB 200 2011)\n",
    "unlabeled_data_dir = data_path(\"CUB_200_2011/CUB_200_2011/images\", is_local=is_local)\n",
    "unlabeled_dataset = datasets.ImageFolder(\n",
    "    unlabeled_data_dir, data_transforms['train'])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure teacher model's architecture\n",
    "teacher = models.resnet50()\n",
    "\n",
    "# Augment last layer to match dimensions\n",
    "num_classes = 200\n",
    "num_ftrs = teacher.fc.in_features\n",
    "teacher.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "teacher = teacher.to(device)\n",
    "\n",
    "# Load in trained model as teacher\n",
    "teacher.load_state_dict(torch.load(TRAINED_MODEL_PATH, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment: Evaluate trained model's performance on unlabeled data\n",
    "teacher.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_corrects = 0\n",
    "    seen = 0\n",
    "    for i, (inputs, labels) in enumerate(unlabeled_dataloader):\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        outputs = teacher(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        print(preds)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        seen += len(inputs)\n",
    "        print(running_corrects, \"/\", seen, running_corrects / seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs\n",
    "sm = nn.Softmax(dim=1)\n",
    "probs = sm(outputs)\n",
    "\n",
    "# sanity check\n",
    "assert abs(torch.sum(probs[0]) - 1) <= 0.005\n",
    "\n",
    "print(torch.max(probs, dim=1).values)\n",
    "print(torch.max(probs, dim=1).values > 0.75)\n",
    "valid_confidence = torch.max(probs, dim=1).values > 0.3\n",
    "probs[valid_confidence].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataset.__getitem__(2)\n",
    "teacher(labeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sm = nn.Softmax(dim=1)\n",
    "\n",
    "# Write a dataloader that randomly picks either the pseudo labeled or correctly labeled data\n",
    "class StudentDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, teacher, labeled, unlabeled, transform=None):\n",
    "        self.teacher = teacher\n",
    "        self.labeled = labeled\n",
    "        self.unlabeled = unlabeled\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labeled) + len(self.unlabeled)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx < len(self.labeled):\n",
    "#             print(\"labeled\")\n",
    "            return self.labeled.__getitem__(idx)\n",
    "        \n",
    "        idx = idx - len(self.labeled)\n",
    "#         print(\"unlabeled\")\n",
    "        img, truelabel = self.unlabeled.__getitem__(idx)\n",
    "        logits = self.teacher(torch.reshape(img, (1, 3, 224, 224)))\n",
    "        probs = sm(logits)\n",
    "        value, prediction = torch.max(probs, dim=1)\n",
    "        pseudolabel = int(prediction)\n",
    "#         if value < 0.75:\n",
    "#             print(\"LOW CONF\", truelabel, pseudolabel)\n",
    "#             return img, -1\n",
    "#         print(truelabel, pseudolabel, value)\n",
    "        return img, pseudolabel\n",
    "    \n",
    "s = StudentDataset(teacher, labeled_dataset, unlabeled_dataset)\n",
    "\n",
    "# for i, (img, label) in enumerate(s):\n",
    "#     if i > len(s.labeled):\n",
    "#         print(i)\n",
    "# print(labeled_dataset.__getitem__(0))\n",
    "# print(s.__getitem__(0))\n",
    "\n",
    "# # print(unlabeled_dataset.__getitem__(0))\n",
    "# for i in range(len(s.labeled), len(s), 30):\n",
    "#     print(s.__getitem__(i))\n",
    "# print(len(s.labeled))\n",
    "# print(len(s.unlabeled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = s.__getitem__(0)\n",
    "print(img.shape)\n",
    "\n",
    "logits = teacher(torch.reshape(img, (1, 3, 224, 224)))\n",
    "probs = sm(logits)\n",
    "value, prediction = torch.max(probs, dim=1)\n",
    "\n",
    "print(value, value > 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_loader = torch.utils.data.DataLoader(s, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe only keep those > 0.85 \n",
    "for i, j in combined_loader:\n",
    "    print(j)\n",
    "#     valid = j > 0\n",
    "#     print(torch.sum(valid))\n",
    "#     print(i[valid].shape)\n",
    "#     print(j[valid].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure student model's architecture\n",
    "student = models.resnet50()\n",
    "\n",
    "# Augment last layer to match dimensions\n",
    "num_classes = 200\n",
    "num_ftrs = student.fc.in_features\n",
    "student.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "student = student.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_print(i):\n",
    "    print_every = 15 if is_local else 200\n",
    "    return i % print_every == 0\n",
    "\n",
    "sm = nn.Softmax(dim=1)\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    # track best model weights\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # train for num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a phase: train and val\n",
    "        for phase in ['train', 'val']:\n",
    "            epoch_begin = time.time()\n",
    "            if phase == 'train':\n",
    "                # sets it in training mode\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # get batch\n",
    "            for i, (inputs, labels) in enumerate(combined_loader):\n",
    "                valid = labels != -1\n",
    "                print(valid)\n",
    "                print(inputs.shape)\n",
    "                inputs = inputs[valid]\n",
    "                labels = labels[valid]\n",
    "                print(torch.sum(valid))\n",
    "                print(inputs.shape)\n",
    "                print(labels.shape)\n",
    "                print(labels)\n",
    "                if should_print(i):\n",
    "                    time_elapsed = time.time() - epoch_begin\n",
    "                    print(\n",
    "                        i + 1, '/', len(combined_loader), int(time_elapsed), 'seconds')\n",
    "                    print('ETA:', datetime.timedelta(seconds=int(\n",
    "                        (time_elapsed / (i + 1)) * (len(combined_loader) - i))))\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero out the previous gradient\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # dunno what this `with` does\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # forward pass\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            print(running_corrects.double(), \"/\", dataset_sizes[phase])\n",
    "            print(running_corrects.double() / dataset_sizes[phase])\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                print(\"UPDATE:\", best_acc, \"to\", epoch_acc)\n",
    "                print(\"Saving model to\", PATH)\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(model.state_dict(), PATH)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(student.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "\n",
    "student = train_model(student, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "class PseudolabelDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, teacher, threshold=0, device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        self.data = data\n",
    "        self.teacher = teacher\n",
    "        self.threshold = threshold\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, _ = self.data.__getitem__(idx)\n",
    "        img = img.to(self.device)\n",
    "\n",
    "        logits = self.teacher(torch.reshape(img, (1, 3, 224, 224)))\n",
    "        probs = softmax(logits)\n",
    "        value, prediction = torch.max(probs, dim=1)\n",
    "        pseudolabel = int(prediction)\n",
    "        if value < self.threshold:\n",
    "            return img, -1\n",
    "        return img, pseudolabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd = PseudolabelDataset(unlabeled_dataset, teacher, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, (i, j) in enumerate(pd):\n",
    "    if num == 0:\n",
    "        print(i)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
